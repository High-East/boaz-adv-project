{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from os import chdir\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from V2I import video2image\n",
    "import datetime\n",
    "from moviepy.editor import *\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# from keras.models import load_model\n",
    "# my_vgg = load_model('finetuned_vgg.h5')\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "my_vgg = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 128\n",
    "width = 128\n",
    "seq_len = 30\n",
    "ms = 200\n",
    "\n",
    "video_wd = '/Users/seogeurim/Desktop/FallDownDetection_Tobigs/TestData/'\n",
    "model_saving_wd = '/Users/seogeurim/Desktop/FallDownDetection_Tobigs/Model1/Model_Saved_real/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-11-20 08:04:45.538472\n",
      "DSSTORE=====\n",
      "1 videos done.\n",
      "2 videos done.\n",
      "3 videos done.\n",
      "4 videos done.\n",
      "5 videos done.\n",
      "6 videos done.\n",
      "7 videos done.\n",
      "8 videos done.\n",
      "9 videos done.\n",
      "10 videos done.\n",
      "11 videos done.\n",
      "12 videos done.\n",
      "13 videos done.\n",
      "14 videos done.\n",
      "15 videos done.\n",
      "16 videos done.\n",
      "17 videos done.\n",
      "18 videos done.\n",
      "19 videos done.\n",
      "20 videos done.\n",
      "21 videos done.\n",
      "22 videos done.\n",
      "23 videos done.\n",
      "24 videos done.\n",
      "25 videos done.\n",
      "26 videos done.\n",
      "27 videos done.\n",
      "28 videos done.\n",
      "29 videos done.\n",
      "30 videos done.\n",
      "31 videos done.\n",
      "32 videos done.\n",
      "33 videos done.\n",
      "34 videos done.\n",
      "35 videos done.\n",
      "36 videos done.\n",
      "37 videos done.\n",
      "38 videos done.\n",
      "39 videos done.\n",
      "40 videos done.\n",
      "41 videos done.\n",
      "42 videos done.\n",
      "43 videos done.\n",
      "44 videos done.\n",
      "45 videos done.\n",
      "46 videos done.\n",
      "47 videos done.\n",
      "48 videos done.\n",
      "49 videos done.\n",
      "50 videos done.\n",
      "2019-11-20 08:05:14.658757\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "data = np.zeros(128 * 128 * 3 * 30).reshape([1, 30, 128, 128, 3])\n",
    "label = []\n",
    "count = []\n",
    "i = 0\n",
    "for path, dir, files in os.walk(video_wd):\n",
    "    if path == video_wd + 'NonViolence':\n",
    "        idx = 0  # no _violence\n",
    "    elif path == video_wd + 'Violence':\n",
    "        idx = 1  # Violence\n",
    "    for file in files:\n",
    "        if file == '.DS_Store':\n",
    "            print(\"DSSTORE=====\")\n",
    "        else:\n",
    "            wd_file = path + '/' + file\n",
    "            cnt, clips = video2image(wd=video_wd,\n",
    "                                     video=wd_file,\n",
    "                                     width=width,\n",
    "                                     height=height,\n",
    "                                     ms=ms,\n",
    "                                     seq_len=seq_len,\n",
    "                                     standard=50)\n",
    "            data = np.concatenate([data, np.array(clips).reshape([1, 30, 128, 128, 3])], axis=0)\n",
    "            label.append(idx)\n",
    "            count.append(cnt)\n",
    "            i += 1\n",
    "            print('{} videos done.'.format(i))\n",
    "label = np.array(label)\n",
    "count = np.array(count)\n",
    "count[count > seq_len] = seq_len\n",
    "data = data[1:]\n",
    "ch_to_idx = {'Violence': 1, 'NonViolence': 0}\n",
    "n_videos = len(data)\n",
    "n_class = len(ch_to_idx)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "(50, 30, 8192)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "data_ftmap = np.zeros(30 * 4 * 4 * 512).reshape([1, 30, 4 * 4 * 512])\n",
    "for i in range(len(data)):\n",
    "    data_ftmap = np.concatenate([data_ftmap, my_vgg.predict(data[i]).reshape(1, seq_len, -1)], axis=0)\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "\n",
    "data_ftmap = data_ftmap[1:]\n",
    "\n",
    "print(np.shape(data_ftmap))\n",
    "print(np.shape(count))\n",
    "print(np.shape(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 30, 8192)\n",
      "(50,)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "test_x = data_ftmap\n",
    "test_y = label\n",
    "test_count = count\n",
    "\n",
    "print(np.shape(test_x))\n",
    "print(np.shape(test_y))\n",
    "print(np.shape(test_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy :  0.56\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[17 16 16 16 11 12 16 14 15 14 18 19 17 14 16 17  9 14 17 12 16 14 13 17\n",
      " 15 21 24  9 28 13 20 15 26 17 26  6 24 30 21 23  7 20 18 18 17 19  8 26\n",
      " 25  7]\n",
      "test accuracy :  nan\n",
      "[]\n",
      "[]\n",
      "col_0   0   1\n",
      "row_0        \n",
      "0.0    15  10\n",
      "1.0    10  15\n"
     ]
    }
   ],
   "source": [
    "total_result = []\n",
    "batch_size = 50\n",
    "trying = 0  # 1st Model\n",
    "\n",
    "tf.reset_default_graph()\n",
    "test_graph = tf.Graph()\n",
    "with tf.Session(graph=test_graph) as sess:\n",
    "    loader = tf.train.import_meta_graph(model_saving_wd + str(trying) + '_Model.ckpt.meta')\n",
    "    loader.restore(sess, model_saving_wd + str(trying) + '_Model.ckpt')\n",
    "\n",
    "    LSTM_x = test_graph.get_tensor_by_name(name='LSTM_x:0')\n",
    "    LSTM_y = test_graph.get_tensor_by_name(name='LSTM_y:0')\n",
    "    LSTM_count = test_graph.get_tensor_by_name(name='LSTM_count:0')\n",
    "    pred = test_graph.get_tensor_by_name(name='pred:0')\n",
    "    acc = test_graph.get_tensor_by_name(name='acc:0')\n",
    "\n",
    "    for i in range(int(len(test_x) / batch_size) + 1):\n",
    "        if i == int(n_videos / batch_size):  # 배치 다돌고 나머지 처리할떄\n",
    "            batch_test_x = test_x[i * batch_size:]\n",
    "            batch_label = test_y[i * batch_size:]\n",
    "            batch_count = test_count[i * batch_size:]\n",
    "\n",
    "        else:\n",
    "            batch_test_x = test_x[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_label = test_y[i * batch_size:(i + 1) * batch_size]\n",
    "            batch_count = test_count[i * batch_size:(i + 1) * batch_size]\n",
    "\n",
    "        print('test accuracy : ', sess.run(acc, feed_dict={LSTM_x: batch_test_x,\n",
    "                                                           LSTM_y: batch_label,\n",
    "                                                           LSTM_count: batch_count}))\n",
    "        prediction = sess.run(pred, feed_dict={LSTM_x: batch_test_x,\n",
    "                                               LSTM_count: batch_count})\n",
    "        print(batch_label)\n",
    "        print(batch_count)\n",
    "\n",
    "        total_result += list(prediction)\n",
    "\n",
    "print(pd.crosstab(np.array(total_result), test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
